# emotion_recognition.py

"""
Emotion Recognition from Speech
-------------------------------
Build a model that recognizes emotions in speech using deep learning and
speech processing techniques.
"""

import os
import librosa
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import librosa.display
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM
from tensorflow.keras.utils import to_categorical

# === Load Dataset ===
# Assume the dataset is organized in folders by emotion labels
# Example: data/happy/*.wav, data/sad/*.wav, etc.
data_dir = "data/"
emotions = os.listdir(data_dir)

features = []
labels = []

# === Feature Extraction ===
def extract_features(file_path):
    y, sr = librosa.load(file_path, duration=3, offset=0.5)
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)
    mfcc_scaled = np.mean(mfcc.T, axis=0)
    return mfcc_scaled

# Process all audio files
for emotion in emotions:
    emotion_path = os.path.join(data_dir, emotion)
    for file in os.listdir(emotion_path):
        if file.endswith(".wav"):
            file_path = os.path.join(emotion_path, file)
            try:
                mfccs = extract_features(file_path)
                features.append(mfccs)
                labels.append(emotion)
            except Exception as e:
                print(f"Error processing {file_path}: {e}")

# === Prepare Data ===
X = np.array(features)
y = np.array(labels)

le = LabelEncoder()
y_encoded = to_categorical(le.fit_transform(y))

X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

# === Build LSTM Model ===
model = Sequential()
model.add(Dense(256, input_shape=(40,), activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(y_encoded.shape[1], activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

# === Train Model ===
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))

# === Evaluate ===
loss, accuracy = model.evaluate(X_test, y_test)
print(f"\nTest Accuracy: {accuracy * 100:.2f}%")

# === Save Model ===
model.save("models/emotion_recognition_model.h5")

# === Plot Accuracy ===
plt.figure(figsize=(8, 6))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.tight_layout()
plt.savefig("assets/training_accuracy.png")
plt.show()
